{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Write a python program to display all the header tags from‘en.wikipedia.org/wiki/Main_Page’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bs4\n",
    "#!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = soup.find_all(['h1', 'h2','h3','h4','h5','h6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_all = [] \n",
    "\n",
    "for i in titles:\n",
    "    header_all.append(i.text.replace('\\n', ''))\n",
    "    \n",
    "header_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the data in structured format\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "header_data=pd.DataFrame({})\n",
    "header_data['header_tags']=header_all\n",
    "\n",
    "header_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IMDBpage = requests.get('https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc&count=100')\n",
    "IMDBpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDBpage.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=BeautifulSoup(IMDBpage.content)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = df.find_all('h3', class_='lister-item-header')\n",
    "\n",
    "top_100_name = [] \n",
    "\n",
    "for i in series:    \n",
    "    for j in i.find_all('a'):\n",
    "        top_100_name.append(j.text.replace('\\n', ''))\n",
    "\n",
    "        \n",
    "rating = df.find_all('span', class_='lister-item-index unbold text-primary')\n",
    "\n",
    "top_100_rating = [] \n",
    "\n",
    "for i in rating:    \n",
    "        top_100_rating.append(i.text)\n",
    "\n",
    "\n",
    "year = df.find_all('span', class_='lister-item-year text-muted unbold')\n",
    "\n",
    "top_100_year = [] \n",
    "\n",
    "for i in year:    \n",
    "        top_100_year.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top_rated_100=pd.DataFrame({})\n",
    "Top_rated_100['Name']=top_100_name\n",
    "Top_rated_100['IMDB rating']=top_100_rating\n",
    "Top_rated_100['Year of release']=top_100_year\n",
    "\n",
    "Top_rated_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDBpage = requests.get('https://www.imdb.com/list/ls009997493/')\n",
    "IMDBpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=BeautifulSoup(IMDBpage.content)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = df.find_all('h3', class_='lister-item-header')\n",
    "\n",
    "top_100_name = [] \n",
    "\n",
    "for i in series:    \n",
    "    for j in i.find_all('a'):\n",
    "        top_100_name.append(j.text.replace('\\n', ''))\n",
    "\n",
    "        \n",
    "rating = df.find_all('span', class_='lister-item-index unbold text-primary')\n",
    "\n",
    "top_100_rating = [] \n",
    "\n",
    "for i in rating:    \n",
    "        top_100_rating.append(i.text)\n",
    "\n",
    "\n",
    "year = df.find_all('span', class_='lister-item-year text-muted unbold')\n",
    "\n",
    "top_100_year = [] \n",
    "\n",
    "for i in year:    \n",
    "        top_100_year.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top_rated_100_Indian=pd.DataFrame({})\n",
    "Top_rated_100_Indian['Name']=top_100_name\n",
    "Top_rated_100_Indian['IMDB rating']=top_100_rating\n",
    "Top_rated_100_Indian['Year of release']=top_100_year\n",
    "\n",
    "Top_rated_100_Indian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Write a python program to scrap book name, author name, genre and book review of any 5 books from ‘www.bookpage.com’\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookpage = requests.get('https://bookpage.com/search?page=1&utf8=%E2%9C%93')\n",
    "bookpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=BeautifulSoup(bookpage.content)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_name = df.find_all('h4', class_='italic')\n",
    "\n",
    "bookname = []\n",
    "\n",
    "for i in book_name:    \n",
    "    for j in i.find_all('a'):\n",
    "        bookname.append(j.text.replace('★', ''))\n",
    "\n",
    "        \n",
    "bookname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Auth_name = df.find_all('p', class_='sans bold')\n",
    "\n",
    "author = []\n",
    "\n",
    "for i in Auth_name:\n",
    "    author.append(i.text.replace('\\n', '').strip())\n",
    "\n",
    "        \n",
    "author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = df.find_all('p', class_='genre-links hidden-phone')\n",
    "\n",
    "genre_list = []\n",
    "\n",
    "for i in genre:\n",
    "    genre_list.append(i.text.replace('\\n', ''))\n",
    "\n",
    "        \n",
    "genre_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = df.find_all('p', class_='excerpt')\n",
    "\n",
    "review_list = []\n",
    "\n",
    "for i in review:\n",
    "    review_list.append(i.text.replace('\\n', ''))\n",
    "\n",
    "\n",
    "review_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "book_details=pd.DataFrame({})\n",
    "book_details['Name']=bookname\n",
    "book_details['Auther']=author\n",
    "book_details['Genre']=genre_list\n",
    "book_details['Review']=review_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_details.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "## i) Top 10 ODI teams in men’s cricket along with the records for matches, points andrating.\n",
    "## ii) Top 10 ODI Batsmen in men along with the records of their team and rating.\n",
    "## iii) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iccpage = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "iccpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=BeautifulSoup(iccpage.content)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name = df.find_all('tbody')\n",
    "\n",
    "teamname = []\n",
    "\n",
    "for i in team_name:\n",
    "    for j in i.find_all('span', class_='u-hide-phablet'):\n",
    "        teamname.append(j.text.replace('\\n', ''))\n",
    "\n",
    "        \n",
    "teamname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_matches = df.find_all('tbody')\n",
    "\n",
    "matches1 = []\n",
    "\n",
    "for i in no_matches:\n",
    "    for j in i.find_all('td', class_='rankings-block__banner--matches'):\n",
    "        matches1.append(j.text.replace('\\n', ''))\n",
    "\n",
    "        \n",
    "matches2 = []\n",
    "\n",
    "for i in no_matches:\n",
    "    for j in i.find_all('td', class_=('table-body__cell u-center-text')):\n",
    "        matches2.append(j.text.replace('\\n', ''))\n",
    "\n",
    "matches3 = []\n",
    "for i in range (0,len(matches2),2):\n",
    "    matches3.append(matches2[i])\n",
    "\n",
    "\n",
    "no_of_matches=matches1 + matches3\n",
    "no_of_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = df.find('td', class_='rankings-block__banner--points')\n",
    "\n",
    "points1 = []\n",
    "points1.append(points.text)\n",
    "      \n",
    "points2 = []\n",
    "for i in df.find_all('td', class_=('table-body__cell u-center-text')):\n",
    "    points2.append(i.text.replace('\\n', ''))\n",
    "\n",
    "points3 = []\n",
    "for i in range (1,len(points2),2):\n",
    "    points3.append(points2[i])\n",
    "    \n",
    "no_of_points = points1 + points3\n",
    "no_of_points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_details = df.find_all('td', ('rankings-block__banner--rating u-text-right','table-body__cell u-text-right rating'))\n",
    "\n",
    "rating = []\n",
    "\n",
    "for i in rating_details:\n",
    "    rating.append(i.text.replace('\\n', '').strip())\n",
    "\n",
    "        \n",
    "rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### i) Top 10 ODI teams in men’s cricket along with the records for matches, points andrating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odi_men=pd.DataFrame({})\n",
    "odi_men['Team']=teamname\n",
    "odi_men['Matches']=no_of_matches\n",
    "odi_men['Points']=no_of_points\n",
    "odi_men['Rating']=rating\n",
    "\n",
    "odi_men.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "player_details = requests.get(url)\n",
    "df=BeautifulSoup(player_details.content)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player = df.find_all('div', class_='rankings-block__banner--name-large')\n",
    "\n",
    "name = []\n",
    "\n",
    "for i in player:\n",
    "    name.append(i.text.replace('\\n', ''))\n",
    "\n",
    "for i in df.find_all('td', class_='table-body__cell rankings-table__name name'):\n",
    "    name.append(i.text.replace('\\n', ''))\n",
    "        \n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team = []\n",
    "\n",
    "player_team = df.find('div', 'rankings-block__banner--nationality')\n",
    "\n",
    "team.append(player_team.text.replace('\\n', '').strip())\n",
    "\n",
    "for i in df.find_all('span', class_='table-body__logo-text'):\n",
    "    team.append(i.text.replace('\\n', ''))\n",
    "    \n",
    "team\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = []\n",
    "\n",
    "player_rating = df.find('div', 'rankings-block__banner--rating')\n",
    "\n",
    "rating.append(player_rating.text.replace('\\n', '').strip())\n",
    "\n",
    "for i in df.find_all('td', class_='table-body__cell rating'):\n",
    "    rating.append(i.text.replace('\\n', ''))\n",
    "    \n",
    "rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ii) Top 10 ODI Batsmen in men along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batsmen_details=pd.DataFrame({})\n",
    "batsmen_details['Player']=name\n",
    "batsmen_details['Team']=team\n",
    "batsmen_details['Rating']=rating\n",
    "\n",
    "batsmen_details.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "bowler_details = requests.get(url)\n",
    "df=BeautifulSoup(bowler_details.content)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowler = df.find('div', class_='rankings-block__banner--name-large')\n",
    "\n",
    "bowler_name = []\n",
    "\n",
    "bowler_name.append(bowler.text.replace('\\n', ''))\n",
    "\n",
    "for i in df.find_all('td', class_='table-body__cell rankings-table__name name'):\n",
    "    bowler_name.append(i.text.replace('\\n', ''))\n",
    "\n",
    "bowler_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team = []\n",
    "\n",
    "bowler_team = df.find('div', 'rankings-block__banner--nationality')\n",
    "\n",
    "team.append(bowler_team.text.replace('\\n', '').strip())\n",
    "\n",
    "for i in df.find_all('span', class_='table-body__logo-text'):\n",
    "    team.append(i.text.replace('\\n', ''))\n",
    "    \n",
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = []\n",
    "\n",
    "bowler_rating = df.find('div', 'rankings-block__banner--rating')\n",
    "\n",
    "rating.append(bowler_rating.text.replace('\\n', '').strip())\n",
    "\n",
    "for i in df.find_all('td', class_='table-body__cell rating'):\n",
    "    rating.append(i.text.replace('\\n', ''))\n",
    "    \n",
    "rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iii) Top 10 ODI bowlers along with the records of their team andrating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowler_details=pd.DataFrame({})\n",
    "bowler_details['Player']=bowler_name\n",
    "bowler_details['Team']=team\n",
    "bowler_details['Rating']=rating\n",
    "\n",
    "bowler_details.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have toscrape:\n",
    "#### i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "#### ii) Top 10 women’s ODI players along with the records of their team and rating.\n",
    "#### iii) Top 10 women’s ODI all-rounder along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "team_details = requests.get(url)\n",
    "df=BeautifulSoup(team_details.content)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_name = df.find_all('tbody')\n",
    "\n",
    "teamname = []\n",
    "\n",
    "for i in team_name:\n",
    "    for j in i.find_all('span', class_='u-hide-phablet'):\n",
    "        teamname.append(j.text.replace('\\n', ''))\n",
    "\n",
    "        \n",
    "teamname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_matches = df.find_all('tbody')\n",
    "\n",
    "matches1 = []\n",
    "\n",
    "for i in no_matches:\n",
    "    for j in i.find_all('td', class_='rankings-block__banner--matches'):\n",
    "        matches1.append(j.text.replace('\\n', ''))\n",
    "\n",
    "        \n",
    "matches2 = []\n",
    "\n",
    "for i in no_matches:\n",
    "    for j in i.find_all('td', class_=('table-body__cell u-center-text')):\n",
    "        matches2.append(j.text.replace('\\n', ''))\n",
    "\n",
    "matches3 = []\n",
    "for i in range (0,len(matches2),2):\n",
    "    matches3.append(matches2[i])\n",
    "\n",
    "\n",
    "no_of_matches=matches1 + matches3\n",
    "no_of_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = df.find('td', class_='rankings-block__banner--points')\n",
    "\n",
    "points1 = []\n",
    "points1.append(points.text)\n",
    "      \n",
    "points2 = []\n",
    "for i in df.find_all('td', class_=('table-body__cell u-center-text')):\n",
    "    points2.append(i.text.replace('\\n', ''))\n",
    "\n",
    "points3 = []\n",
    "for i in range (1,len(points2),2):\n",
    "    points3.append(points2[i])\n",
    "    \n",
    "no_of_points = points1 + points3\n",
    "no_of_points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_details = df.find_all('td', ('rankings-block__banner--rating u-text-right','table-body__cell u-text-right rating'))\n",
    "\n",
    "rating = []\n",
    "\n",
    "for i in rating_details:\n",
    "    rating.append(i.text.replace('\\n', '').strip())\n",
    "\n",
    "        \n",
    "rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odi_women=pd.DataFrame({})\n",
    "odi_women['Team']=teamname\n",
    "odi_women['Matches']=no_of_matches\n",
    "odi_women['Points']=no_of_points\n",
    "odi_women['Rating']=rating\n",
    "\n",
    "odi_women.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting'\n",
    "player_details = requests.get(url)\n",
    "df=BeautifulSoup(player_details.content)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "player = df.find_all('div', class_='rankings-block__banner--name-large')\n",
    "\n",
    "name = []\n",
    "\n",
    "for i in player:\n",
    "    name.append(i.text.replace('\\n', ''))\n",
    "\n",
    "for i in df.find_all('td', class_='table-body__cell rankings-table__name name'):\n",
    "    name.append(i.text.replace('\\n', ''))\n",
    "        \n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team = []\n",
    "\n",
    "player_team = df.find('div', 'rankings-block__banner--nationality')\n",
    "\n",
    "team.append(player_team.text.replace('\\n', '').strip())\n",
    "\n",
    "for i in df.find_all('span', class_='table-body__logo-text'):\n",
    "    team.append(i.text.replace('\\n', ''))\n",
    "    \n",
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rating = []\n",
    "\n",
    "player_rating = df.find('div', 'rankings-block__banner--rating')\n",
    "\n",
    "rating.append(player_rating.text.replace('\\n', '').strip())\n",
    "\n",
    "for i in df.find_all('td', class_='table-body__cell rating'):\n",
    "    rating.append(i.text.replace('\\n', ''))\n",
    "    \n",
    "rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ii) Top 10 women’s ODI players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "women_details=pd.DataFrame({})\n",
    "women_details['Player']=name\n",
    "women_details['Team']=team\n",
    "women_details['Rating']=rating\n",
    "\n",
    "women_details.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder'\n",
    "player_details = requests.get(url)\n",
    "df=BeautifulSoup(player_details.content)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player = df.find_all('div', class_='rankings-block__banner--name-large')\n",
    "\n",
    "name = []\n",
    "\n",
    "for i in player:\n",
    "    name.append(i.text.replace('\\n', ''))\n",
    "\n",
    "for i in df.find_all('td', class_='table-body__cell rankings-table__name name'):\n",
    "    name.append(i.text.replace('\\n', ''))\n",
    "        \n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team = []\n",
    "\n",
    "player_team = df.find('div', 'rankings-block__banner--nationality')\n",
    "\n",
    "team.append(player_team.text.replace('\\n', '').strip())\n",
    "\n",
    "for i in df.find_all('span', class_='table-body__logo-text'):\n",
    "    team.append(i.text.replace('\\n', ''))\n",
    "    \n",
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = []\n",
    "\n",
    "player_rating = df.find('div', 'rankings-block__banner--rating')\n",
    "\n",
    "rating.append(player_rating.text.replace('\\n', '').strip())\n",
    "\n",
    "for i in df.find_all('td', class_='table-body__cell rating'):\n",
    "    rating.append(i.text.replace('\\n', ''))\n",
    "    \n",
    "rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iii) Top 10 women’s ODI all-rounder along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "women_allround=pd.DataFrame({})\n",
    "women_allround['Allrounder Player']=name\n",
    "women_allround['Team']=team\n",
    "women_allround['Rating']=rating\n",
    "\n",
    "women_allround.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL and Average Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.amazon.in/Mobile-Phone-Under-20000-Rupees/s?k=Mobile+Phone+Under+20000+Rupees'\n",
    "amazpage = requests.get(url)\n",
    "amazpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=BeautifulSoup(amazpage.content)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mob_name = df.find_all('span', class_='a-size-medium a-color-base a-text-normal')\n",
    "\n",
    "mobname = []\n",
    "\n",
    "for i in mob_name:\n",
    "    mobname.append(i.text.replace('\\n', ''))\n",
    "\n",
    "        \n",
    "mobname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_list = df.find_all('span', class_='a-price-whole')\n",
    "\n",
    "price = []\n",
    "\n",
    "for i in price_list:\n",
    "    price.append(i.text.replace('\\n', ''))\n",
    "\n",
    "        \n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#URL for image \n",
    "\n",
    "img_url = df.find_all('img', class_='s-image')\n",
    "img_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = []\n",
    "\n",
    "for i in img_url:\n",
    "    image.append(i.get('src'))\n",
    "\n",
    "        \n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_list = df.find_all('a', class_='a-popover-trigger a-declarative')\n",
    "\n",
    "rating = []\n",
    "\n",
    "for i in rate_list:\n",
    "    rating.append(i.text.replace('out of 5 stars', ''))\n",
    "\n",
    "\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mob_details=pd.DataFrame({})\n",
    "mob_details['Name']=mobname\n",
    "mob_details['Price']=price\n",
    "mob_details['Img URL']= image\n",
    "mob_details['Rating']=rating\n",
    "\n",
    "mob_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Write a python program to extract information about the local weather from the National Weather Service website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day extended forecast display for the city. The data should include period, short description, temperature and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherpage = requests.get('https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YSjy0Y4zZPY')\n",
    "weatherpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=BeautifulSoup(weatherpage.content)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Period_name = df.find_all('p', class_='period-name')\n",
    "\n",
    "day = []\n",
    "\n",
    "for i in Period_name:\n",
    "    day.append(i.text.replace('\\n', ''))\n",
    "\n",
    "        \n",
    "day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_desc = df.find_all('p', class_='short-desc')\n",
    "\n",
    "shortdesc = []\n",
    "\n",
    "for i in short_desc:\n",
    "    shortdesc.append(i.text.replace('\\n', ' '))\n",
    "\n",
    "        \n",
    "shortdesc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_desc = df.find_all('p', class_=('temp temp-high','temp temp-low') )\n",
    "\n",
    "temperature = []\n",
    "\n",
    "for i in temp_desc:\n",
    "    temperature.append(i.text.replace('\\n', ' '))\n",
    "\n",
    "        \n",
    "temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_desc = df.find_all('div', class_=('col-sm-10 forecast-text') )\n",
    "\n",
    "description = []\n",
    "\n",
    "for i in detail_desc:\n",
    "    description.append(i.text.replace('\\n', ''))\n",
    "\n",
    "        \n",
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detaildesc=description[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_report=pd.DataFrame({})\n",
    "weather_report['Period']=day\n",
    "weather_report['short description']=shortdesc\n",
    "weather_report['temperature']=temperature\n",
    "weather_report['description']=detaildesc\n",
    "\n",
    "weather_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Write a python program to scrape fresher job listings from ‘https://internshala.com/’. It should include job title, company name, CTC, and apply date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresherjob = requests.get('https://internshala.com/fresher-jobs')\n",
    "fresherjob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=BeautifulSoup(fresherjob.content)\n",
    "\n",
    "job_title = df.find_all('div', class_='heading_4_5 profile')\n",
    "\n",
    "Title = []\n",
    "\n",
    "for i in job_title:\n",
    "    Title.append(i.text.replace('\\n', ''))\n",
    "\n",
    "        \n",
    "Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_name = df.find_all('a', class_='link_display_like_text')\n",
    "\n",
    "Name = []\n",
    "\n",
    "for i in comp_name:\n",
    "    Name.append(i.text.replace('\\n','').strip())\n",
    "\n",
    "        \n",
    "Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctc = df.find_all('div', class_='item_body')\n",
    "\n",
    "CTC = []\n",
    "job_info = []\n",
    "\n",
    "for i in ctc:\n",
    "    job_info.append(i.text.replace('\\n', '').strip())\n",
    "\n",
    "\n",
    "job_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range (1,len(job_info),3):\n",
    "    CTC.append(job_info[i])\n",
    "    \n",
    "CTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_date = []\n",
    "\n",
    "for i in range (2,len(job_info),3):\n",
    "    apply_date.append(job_info[i])\n",
    "    \n",
    "apply_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresher_jobs=pd.DataFrame({})\n",
    "fresher_jobs['Job title']=Title\n",
    "fresher_jobs['Company Name']=Name\n",
    "fresher_jobs['CTC']=CTC\n",
    "fresher_jobs['Apply Date']=apply_date\n",
    "\n",
    "fresher_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Write a python program to scrape house details from https://www.nobroker.in/ for any location. It should include house title, location, area, emi and price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.nobroker.in/property/sale/hyderabad/Gachibowli?searchParam=W3sibGF0IjoxNy40NDAwODAyLCJsb24iOjc4LjM0ODkxNjgsInBsYWNlSWQiOiJDaElKMzg3ZWRxS1R5enNSNGtTVGI1N25FaXciLCJwbGFjZU5hbWUiOiJHYWNoaWJvd2xpIn1d&radius=2.0'\n",
    "\n",
    "house = requests.get(url)\n",
    "house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=BeautifulSoup(house.content)\n",
    "\n",
    "house_title = df.find_all('h2', class_='heading-6 font-semi-bold nb__1AShY')\n",
    "\n",
    "title = []\n",
    "\n",
    "for i in house_title:\n",
    "    title.append(i.text.replace('\\n', ''))\n",
    "\n",
    "        \n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_location = df.find_all('div', class_='nb__2CMjv')\n",
    "\n",
    "location = []\n",
    "\n",
    "for i in area_location:\n",
    "    location.append(i.text.replace('\\n', ''))\n",
    "\n",
    "        \n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_details = df.find_all('div', class_='font-semi-bold heading-6')\n",
    "\n",
    "emi = []\n",
    "price = []\n",
    "house_info = []\n",
    "\n",
    "for i in house_details:\n",
    "    house_info.append(i.text.replace('\\n','').strip())\n",
    "\n",
    "\n",
    "house_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (1,len(house_info),3):\n",
    "    emi.append(house_info[i])\n",
    "    \n",
    "emi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (2,len(house_info),3):\n",
    "    price.append(house_info[i])\n",
    "    \n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "House_details=pd.DataFrame({})\n",
    "House_details['House title']=title\n",
    "House_details['Area Location']=location\n",
    "House_details['EMI']=emi\n",
    "House_details['Price']=price\n",
    "\n",
    "House_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
